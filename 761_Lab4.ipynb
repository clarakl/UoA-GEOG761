{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clarakl/UoA-GEOG761/blob/main/761_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 4: Deep Learning for Satellite Data\n",
        "This notebook uses a pre-made training dataset to develop a simple deep learning classifier for finding solar pannels in Sentinel 2 imagery. The learning objectives for this lab are to:\n",
        "\n",
        "1. Load and use a pre-labeled training dataset (e.g. polygons or patches with land cover classes).\n",
        "2. Prepare that data for use in a deep learning model.\n",
        "3. Train a deep learning model in TensorFlow/Keras using these labels.\n",
        "\n",
        "At the end of the lab you will be asked to reflect on model performance, generalization, and sources of error.\n"
      ],
      "metadata": {
        "id": "yhu_D7hJyqEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etRkmr2KmKsC"
      },
      "outputs": [],
      "source": [
        "# Set up, couple of new libraries here so expect install times to take longer than you have been used to\n",
        "!pip install -q tensorflow rasterio geemap matplotlib scikit-learn tqdm --quiet\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import re\n",
        "import rasterio\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set our random seeds for reproducibility\n",
        "SEED = 42 #<- the meaning of life, this is why you always see people setting seeds to 42 by the way...\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "A-UXlkz38BKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your training data has been downloaded from:\n",
        "\n",
        "*   [Solafune](https://solafune.com/competitions/5dfc315c-1b24-4573-804f-7de8d707cd90?id=&menu=data&topicId=54728653-0e25-4975-baad-6fe2f5185844)\n",
        "\n",
        "Find the data on Canvas or download directly from their website the 'train.zip'. The competition that this dataset was created for is now over, but that is good for us as it means you can look at the winning solutions for inspiration!\n",
        "\n",
        "If you want to download the data yourself you will need to sign up for an account and then 'enter' the competition. You can do this all without charge but it does require an email address sign up.\n",
        "\n",
        "We are just going to use the 'train.zip' data and split that into our train and test, in order to reduce the burden on our notebooks. Remember that ultimately we would want to validate it, and you will see that the linked data source actually has a completely seperate store of images for that purpose.\n",
        "\n",
        "Take that .zip file and get it into your g-drive/local space as per usual practice. Leave it zipped.\n"
      ],
      "metadata": {
        "id": "WAKL3TAJ1yVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume train.zip is already uploaded to Colab file store, extract it\n",
        "zip_path = \"/content/train.zip\"\n",
        "extract_dir = Path(\"/content/train_data\")\n",
        "extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "  z.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "HucYCi6g1vDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our data extracted, we now need to build lists of each sample patch and the labelled mask of it, connecting the two. I have written this relatively robustly (e.g. you can set it to handle different file extensions and it checks that it is finding the correct files), so that hopefully you can use it more widely than just in this lab."
      ],
      "metadata": {
        "id": "hvY9rN2Z7tw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the file extenion we are using\n",
        "f_ex = \"*.tif\"\n",
        "\n",
        "# Locate directories\n",
        "s2_dir = next((p for p in extract_dir.rglob('*') if p.is_dir() and 's2_image' in p.name.lower()), None)\n",
        "mask_dir = next((p for p in extract_dir.rglob('*') if p.is_dir() and 'mask' in p.name.lower()), None)\n",
        "\n",
        "assert s2_dir and mask_dir, \"Could not locate s2_image/ and mask/ directories.\"\n",
        "print(\"Found Sentinel-2 image dir:\", s2_dir)\n",
        "print(\"Found mask dir:\", mask_dir)\n",
        "\n",
        "# Match files to each other from each sub-directory by trailing numeric ID\n",
        "s2_files = {re.search(r'_(\\d+)\\.tif$', f.name).group(1): f for f in Path(s2_dir).glob(f_ex)}\n",
        "mask_files = {re.search(r'_(\\d+)\\.tif$', f.name).group(1): f for f in Path(mask_dir).glob(f_ex)}\n",
        "\n",
        "# Build pairs of images and masks\n",
        "common_ids = sorted(set(s2_files.keys()) & set(mask_files.keys()))\n",
        "assert len(common_ids) > 0, \"No paired s2_image/mask files found with matching IDs.\"\n",
        "\n",
        "pairs = []\n",
        "for i in common_ids:\n",
        "    s2_path, mask_path = s2_files[i], mask_files[i]\n",
        "    with rasterio.open(s2_path) as s2, rasterio.open(mask_path) as m:\n",
        "        assert (s2.height, s2.width) == (m.height, m.width), \\\n",
        "            f\"Shape mismatch: {s2_path.name} vs {mask_path.name}\"\n",
        "    pairs.append((s2_path, mask_path))\n",
        "\n",
        "print(f\"Found {len(pairs)} valid paired samples.\")\n",
        "print(\"Example pair:\", pairs[0])"
      ],
      "metadata": {
        "id": "cG8V43A37tan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick sanity check: visualize one random pair out of the first 31 available\n",
        "# Run this cell a few times to check that you have different files and that the mask looks about right\n",
        "pair_num = np.random.randint(0,30)\n",
        "s2_path, mask_path = pairs[pair_num]\n",
        "\n",
        "with rasterio.open(s2_path) as src:\n",
        "    s2_img = src.read([3,2,1])  # RGB bands for Sentinel-2 (B4, B3, B2)\n",
        "    s2_img = np.transpose(s2_img, (1,2,0))\n",
        "    s2_img = (s2_img - s2_img.min()) / (s2_img.max() - s2_img.min()) # min/max normalization to have the lowest value be 0 and the highest be 1 to use the full range, if we would not substract the min we would lose some range\n",
        "\n",
        "with rasterio.open(mask_path) as src:\n",
        "    mask = src.read(1)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(s2_img)\n",
        "plt.title(\"Sentinel-2 RGB Patch\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(mask, cmap=\"gray\")\n",
        "plt.title(\"Mask\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hzij3jXU-SNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next up we are going to prepare our training data into numpy arrays that are then able to be passed into TensorFlow. However, if we try to hold all 2000+ patches in RAM whilst we do, the Colab instance will crash. If on your own laptop, it will also die unless you have spent a lot more money than I have on mine. Furthermore, even if we had a HPC level of RAM available it is a good idea to do things in a 'memory safe' manner that means we can scale our training with more samples if we so desired it.\n",
        "\n",
        "The safe pattern is therefore to:\n",
        "1. Load a batch of patches.\n",
        "2. Normalize/resize them.\n",
        "3. Save them to disk (e.g. as .npy, .npz, or TFRecords/HDF5).\n",
        "4. Free memory and move on.\n",
        "5. Then later, when training, you stream batches directly from disk.\n",
        "\n",
        "Here’s a disk-based pipeline with batching using numpy.savez_compressed (safe + easy to reload):"
      ],
      "metadata": {
        "id": "ldr_zbvV_L8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_or_pad(arr, target_h, target_w):\n",
        "    h, w = arr.shape[:2]\n",
        "    c = arr.shape[2] if arr.ndim == 3 else 1\n",
        "\n",
        "    arr = cv2.resize(\n",
        "        arr,\n",
        "        (target_w, target_h),\n",
        "        interpolation=cv2.INTER_NEAREST if c == 1 else cv2.INTER_LINEAR)\n",
        "\n",
        "    if arr.ndim == 2:\n",
        "        arr = arr[..., np.newaxis]\n",
        "    return arr\n",
        "\n",
        "\n",
        "# Set storage folder\n",
        "OUTPUT_DIR = \"patch_store\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "TARGET_HEIGHT, TARGET_WIDTH = 256, 256 # Tune based on memory available\n",
        "BATCH_SIZE = 100  # Tune based on memory available\n",
        "\n",
        "\n",
        "X_batch, Y_batch = [], []\n",
        "batch_idx = 0\n",
        "\n",
        "for i, (s2_path, mask_path) in enumerate(tqdm(pairs, desc=\"Processing\")):\n",
        "    # tqdm is positioned so that it wraps the iterable in the for loop\n",
        "    # Load Sentinel-2\n",
        "    with rasterio.open(s2_path) as src:\n",
        "        img = src.read().astype(np.float32)  # (bands, H, W)\n",
        "        img = np.transpose(img, (1, 2, 0))  # (H, W, bands)\n",
        "\n",
        "    # Load mask\n",
        "    with rasterio.open(mask_path) as src:\n",
        "        mask = src.read(1).astype(np.uint8)\n",
        "\n",
        "    # Resize/pad\n",
        "    img = resize_or_pad(img, TARGET_HEIGHT, TARGET_WIDTH)\n",
        "    mask = resize_or_pad(mask, TARGET_HEIGHT, TARGET_WIDTH)\n",
        "\n",
        "    # Normalize\n",
        "    img = img / 10000.0\n",
        "\n",
        "    # Add to batch\n",
        "    X_batch.append(img)\n",
        "    Y_batch.append(mask)\n",
        "\n",
        "    # Save batch to disk when full\n",
        "    if len(X_batch) >= BATCH_SIZE:\n",
        "        X_batch = np.stack(X_batch)\n",
        "        Y_batch = np.stack(Y_batch)\n",
        "\n",
        "        np.savez_compressed(\n",
        "            os.path.join(OUTPUT_DIR, f\"batch_{batch_idx:04d}.npz\"),\n",
        "            X=X_batch, Y=Y_batch\n",
        "        )\n",
        "\n",
        "        # Reset\n",
        "        batch_idx += 1\n",
        "        X_batch, Y_batch = [], []\n",
        "\n",
        "# Save any leftovers\n",
        "# If the last few images don't add up to 100, you still want to save them, just not in a batch of 100 but whatever number of images is left\n",
        "if len(X_batch) > 0:\n",
        "    X_batch = np.stack(X_batch)\n",
        "    Y_batch = np.stack(Y_batch)\n",
        "    np.savez_compressed(\n",
        "        os.path.join(OUTPUT_DIR, f\"batch_{batch_idx:04d}.npz\"),\n",
        "        X=X_batch, Y=Y_batch\n",
        "    )\n",
        "\n",
        "# By the way it is the 'tqdm' element that is providing the nifty progress bar. I always like to include it when waiting for things so that I know it is actually running.\n",
        "\n",
        "# This block might take five to ten minutes to run as we are doing this in a linear manner (rather than parallell processing).\n",
        "# An optimised version of thise code is to pass each batch to a seperate CPU thread/core."
      ],
      "metadata": {
        "id": "bf8AmhFm_N0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-10 minutes later... (mine took 8 minutes and 32 seconds), we can now move on. Because we are now not storing our training data in our RAM like we did in the lecture exercise, we have to load it in as we want it."
      ],
      "metadata": {
        "id": "RSRtw0_ddyfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First up, set a bunch of parameters that we can modify in order to save our RAM load. In short, the lower these values the less RAM you will use but the worse the results:"
      ],
      "metadata": {
        "id": "k5kavUyxfWEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paramaters for RAM saving\n",
        "TARGET_HEIGHT, TARGET_WIDTH = 128, 128  # smaller patch -> saves RAM & compute\n",
        "BANDS = 3  # RGB only -> reduces memory\n",
        "BATCH_SIZE = 4  # small batch -> reduces RAM usage\n",
        "MAX_TRAIN_FILES = 5  # only use subset for lab demonstration. this is the number of batches, so 5 x 100 patches\n",
        "MAX_VAL_FILES = 2"
      ],
      "metadata": {
        "id": "Jgz5V8ZdwcP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1**: We have used three bands here. What is the total numnber of bands we could make available to the CNN if we so chose?"
      ],
      "metadata": {
        "id": "MK9MDZr43tai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1: Sentinel-2 has a total of 13 bands, which are also included in our data as written in the description of the competition on Solafune: 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B10', 'B11', 'B12'."
      ],
      "metadata": {
        "id": "A23vs-uI5-NI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we find our patch files:"
      ],
      "metadata": {
        "id": "VkWpwojiwhbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set our random seeds for reproducibility\n",
        "SEED = 42 #<- the meaning of life, this is why you always see people setting seeds to 42 by the way...\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "#Putting this here again because everytime I rerun the random shuffle, it continues where it left off with the 42 seed but that does not mean that we get the same shuffling again.\n",
        "\n",
        "# Locate the batched .npz files\n",
        "all_files = sorted(glob.glob(\"patch_store/*.npz\"))\n",
        "np.random.shuffle(all_files)\n",
        "\n",
        "train_files = all_files[:MAX_TRAIN_FILES]\n",
        "val_files   = all_files[-MAX_VAL_FILES:]"
      ],
      "metadata": {
        "id": "IfHUhDLDwjKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_total_patches(file_list):\n",
        "    \"\"\"\n",
        "    Calculates the total number of patches by summing the\n",
        "    patches in each .npz file in the list.\n",
        "    \"\"\"\n",
        "    total_patches = 0\n",
        "    print(\"--- Counting patches in the following files: ---\")\n",
        "    for file_path in file_list:\n",
        "        with np.load(file_path) as data:\n",
        "            num_patches_in_file = data['X'].shape[0]\n",
        "            print(f\"File: {file_path.split('/')[-1]} -> Patches: {num_patches_in_file}\")\n",
        "            total_patches += num_patches_in_file\n",
        "    return total_patches\n",
        "\n",
        "# --- Calculate and print the totals ---\n",
        "if len(all_files) >= (MAX_TRAIN_FILES + MAX_VAL_FILES):\n",
        "    total_train_patches = count_total_patches(train_files)\n",
        "    print(f\"\\n>>> Total training patches: {total_train_patches}\\n\")\n",
        "\n",
        "    total_val_patches = count_total_patches(val_files)\n",
        "    print(f\"\\n>>> Total validation patches: {total_val_patches}\\n\")\n",
        "else:\n",
        "    print(\"Not enough batch files found to create train and validation sets.\")"
      ],
      "metadata": {
        "id": "IqkWnk0LocFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**: What is the total number of patches in our training data and the total number in our validation set? (With the parameters set as I have done in the notebook).\n",
        "\n",
        "Tip: you can either programmatically count what is in train_files/val_files, or you can calculate it from the parameters that have been set across the cells above this one."
      ],
      "metadata": {
        "id": "xz6GToVO4gTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2: Well, you confused me a lot with the random shuffling that you did on the order of the batches, because I thought that we must have 500 patches in the training set (the 5 first batches x 100 patches) and 166 in the validation set (the 2 last batches, of which the last one contains the “leftovers”, and we have 2066 patches in total so this one must contain 66). But, with the shuffling, we ended up using the following batches:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Training data:\n",
        "\n",
        "File: batch_0000.npz -> Patches: 100\n",
        "\n",
        "File: batch_0017.npz -> Patches: 100\n",
        "\n",
        "File: batch_0015.npz -> Patches: 100\n",
        "\n",
        "File: batch_0001.npz -> Patches: 100\n",
        "\n",
        "File: batch_0008.npz -> Patches: 100\n",
        "\n",
        "Total training patches: 500\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Validation data:\n",
        "\n",
        "File: batch_0019.npz -> Patches: 100\n",
        "\n",
        "File: batch_0006.npz -> Patches: 100\n",
        "\n",
        "Total validation patches: 200\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "So, the last two batches were actually batch 19 and batch 6 which both did not happen to be the very last batch that was created, so both had 100.\n"
      ],
      "metadata": {
        "id": "nYxfWYOo6EK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then need to change our masks to a binary label. If we were doing segmenation we would keep it as a mask, but in this case we are just trying to find patches that contain solar pannels rather than the specific solar pannel outline."
      ],
      "metadata": {
        "id": "5VQet50zx6xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask to binary label\n",
        "def mask_to_label(mask_batch):\n",
        "    \"\"\"1 if any solar pixel in mask, else 0\"\"\"\n",
        "    labels = (np.sum(mask_batch, axis=(1,2,3)) > 0).astype(np.float32)\n",
        "    return labels"
      ],
      "metadata": {
        "id": "plCwY8IYyGLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need a tool to load our data in from the batched files:"
      ],
      "metadata": {
        "id": "uQARTP5zyQEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loader\n",
        "def npz_loader_cls(path):\n",
        "    \"\"\"Load one .npz batch, downsample patches, convert to RGB, convert mask to label\"\"\"\n",
        "    data = np.load(path.numpy().decode(\"utf-8\"))\n",
        "    X = data[\"X\"]\n",
        "    Y_mask = data[\"Y\"]\n",
        "\n",
        "    # RAM saving: pick first 3 bands only\n",
        "    X = X[..., :BANDS]\n",
        "\n",
        "    # RAM saving: downsample patches\n",
        "    from skimage.transform import resize\n",
        "    X_resized = np.zeros((X.shape[0], TARGET_HEIGHT, TARGET_WIDTH, BANDS), dtype=np.float32)\n",
        "    for i in range(X.shape[0]):\n",
        "        X_resized[i] = resize(X[i], (TARGET_HEIGHT, TARGET_WIDTH, BANDS), anti_aliasing=True)\n",
        "\n",
        "    X = X_resized\n",
        "\n",
        "    Y = mask_to_label(Y_mask)\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "eH48IPpVehJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now define our training and validation datasets, which will only be actually populated with data as required, rather than loading it all into memory at once."
      ],
      "metadata": {
        "id": "IHjVNIO9gScU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow dataset pipeline\n",
        "def tf_wrapper(path):\n",
        "    X, Y = tf.py_function(npz_loader_cls, [path], [tf.float32, tf.float32])\n",
        "    X.set_shape([None, TARGET_HEIGHT, TARGET_WIDTH, BANDS])\n",
        "    Y.set_shape([None])\n",
        "    # Flatten file-batch into individual samples\n",
        "    return tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "\n",
        "def make_cls_dataset(file_list, batch_size=BATCH_SIZE, shuffle=True, repeat=True):\n",
        "    files = tf.data.Dataset.from_tensor_slices(file_list)\n",
        "    if shuffle:\n",
        "        files = files.shuffle(len(file_list))\n",
        "\n",
        "    # RAM saving: stream samples via interleave\n",
        "    ds = files.interleave(\n",
        "        lambda f: tf_wrapper(f),\n",
        "        cycle_length=4,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(2048)\n",
        "\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    if repeat:\n",
        "        ds = ds.repeat()\n",
        "\n",
        "    return ds\n",
        "\n",
        "train_ds = make_cls_dataset(train_files, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_ds   = make_cls_dataset(val_files, batch_size=BATCH_SIZE, shuffle=False, repeat=False)"
      ],
      "metadata": {
        "id": "-dHkpClEgPp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3**: Are we shuffling the training dataset? Are we shuffling the validation dataset?"
      ],
      "metadata": {
        "id": "ExxsU7IL5n7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3: We are shuffling the training dataset but explicitly disabling it for the validation dataset.\n",
        "Hence training yes, validation no.\n",
        "This is common machine learning practice, a) to avoid the model to learn the order of examples and b) to make sure that the validation dataset stays a consistent benchmark to measure the true progress of the model.\n"
      ],
      "metadata": {
        "id": "yYhM4XUF6aci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to specify our model settings. We are just using a simple CNN here, the same sort as we used the lecture exercise. But, this time it has signficantly more layers and therefore parameters (but far less than you might use for your project). It may take a few minutes to set up:"
      ],
      "metadata": {
        "id": "ZhBQrzrJhKZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are determining the input shape from one batch first\n",
        "for X_sample, _ in train_ds.take(1):\n",
        "    input_shape = X_sample.shape[1:]  # (H, W, bands)\n",
        "    break\n",
        "\n",
        "# Define a simple CNN\n",
        "inputs = layers.Input(shape=input_shape)\n",
        "x = layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
        "x = layers.MaxPooling2D((2,2))(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "y9YqcO1BhIP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4**: Which type of activation function is our final layer using and why are we using this function as our final layer?"
      ],
      "metadata": {
        "id": "m8lBb_Mk553F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A4: We are using sigmoid in our final layer and relu in the hidden layers, which is apparently a common practice. The sigmoid function is very common for binary classification, which is what we are doing here. The function outputs a value between 0 and 1, which can be interpreted as the model's confidence that the input image belongs to the positive class. I see that you have not changed the threshold, so the function will fire at 0.5 and above.\n"
      ],
      "metadata": {
        "id": "O88ZNRcf6eVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the model ready to train, we have one more preperation step to make. We need to count the total samples available in this particular run. This is because you can change the number of samples via the RAM paramaters earlier, and therefore we should assume in this code a static number of samples will always be available when setting our number of steps per epoch."
      ],
      "metadata": {
        "id": "AABBOTGhy4AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total samples\n",
        "def count_samples(files):\n",
        "    total = 0\n",
        "    for f in files:\n",
        "        total += np.load(f)[\"X\"].shape[0]\n",
        "    return total\n",
        "\n",
        "n_train = count_samples(train_files)\n",
        "n_val   = count_samples(val_files)\n",
        "\n",
        "steps_per_epoch = max(1, n_train // BATCH_SIZE)\n",
        "validation_steps = max(1, n_val // BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ckagcnDHy8l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we train the model! It should take 5-10 minutes to run on a free-user Colab notebook."
      ],
      "metadata": {
        "id": "qpg6jT_Zh3af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This 'callbacks' set of instructions is a handy way to avoid wasting time\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",          # Watch the validation loss\n",
        "        patience=3,                  # If it doesn't improve for 3 epochs, stop training\n",
        "        restore_best_weights=True    # Roll back to the best-performing weights\n",
        "    )]\n",
        "\n",
        "# Run the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=5,  # small number for lab demonstration\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "SyHO0Uf9gcC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizie the predictions:"
      ],
      "metadata": {
        "id": "fYyznO5nilZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training curves\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label=\"train\")\n",
        "plt.plot(history.history['val_loss'], label=\"val\")\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label=\"train\")\n",
        "plt.plot(history.history['val_accuracy'], label=\"val\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RGOz-632imi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_patch_predictions_grid(dataset, model, n_rows=2, n_cols=5):\n",
        "    \"\"\"\n",
        "    Display predictions in a grid: n_rows x n_cols\n",
        "    Includes histogram stretch for better visualization of RGB patches.\n",
        "    \"\"\"\n",
        "    def stretch(img):\n",
        "        \"\"\"Contrast stretch to 0–1 for display.\"\"\"\n",
        "        img = img.astype(np.float32)\n",
        "        p2, p98 = np.percentile(img, (2, 98))\n",
        "        img = np.clip((img - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "        return img\n",
        "\n",
        "    for X, Y_true in dataset.take(1):\n",
        "        # live classification of the patch using the trained model\n",
        "        Y_pred = model.predict(X, verbose=0)\n",
        "        n_total = min(n_rows * n_cols, X.shape[0])\n",
        "\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i in range(n_total):\n",
        "            rgb = X[i, :, :, :3].numpy()\n",
        "            rgb = stretch(rgb)  # apply histogram stretch\n",
        "            axes[i].imshow(rgb)\n",
        "            axes[i].set_title(f\"T:{int(Y_true[i].numpy())}\\nP:{Y_pred[i,0]:.2f}\")\n",
        "            axes[i].axis(\"off\")\n",
        "\n",
        "        # hide any unused axes\n",
        "        for i in range(n_total, len(axes)):\n",
        "            axes[i].axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example\n",
        "show_patch_predictions_grid(val_ds, model, n_rows=1, n_cols=5)"
      ],
      "metadata": {
        "id": "KIKyqZr31CGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remembering that this is effectively still a toy CNN with tiny data, we can see that we have built a model that gives us a probability of the patches containing a solar pannel. We know that for all of the patchs used in this training, the answer is true..."
      ],
      "metadata": {
        "id": "iyreuxmU1hcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5**: Is this a robust and reliable model for the detection of solar panels in a new Sentinel 2 image that has never been seen by the model before? Explain your answer with reference to the design of the training data, the settings of the CNN and the performance statistics seen."
      ],
      "metadata": {
        "id": "KhBj404z12H7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5:\n",
        "It’s quite bad I believe, even for being only a demonstration. We chose to use only 500 patches for training although we have 2066 available, and validation is even less. We should aim for something like a 80-10-10 split for training, validation and test, which would result in approximately 1652-207-207 patches respectively. So validation is alright, but we have too few training samples. I also believe that only using the visible light bands loses way too much information, as wavelengths like NIR and SWIR are very useful for distinguishing artificial materials from natural ones. I am not too sure about how badly the downsampling to a resolution of 128x128 affects the performance. I'll think about not doing that for the next question, but I am afraid that leaving the original resolution will drastically increase the computational complexity of my model.\n",
        "\n",
        "As for the CNN architecture, I believe that more convolutional layers would give the model more possibility to learn more features instead of just basic edges or color blobs. But looking at the data that we’re working with, maybe we currently don’t need more. The number of epochs is also, excuse my language, ridiculous, but after I googled it seems like there are very simple models that work with as few as 7-10 epochs, but I believe that we should increase the number of epochs. This would also make the early stop warning with a patience of 3 epochs more meaningful.\n",
        "\n",
        "I believe that the very flat validation accuracy of 0.9150 throughout all of the epochs is a major red flag. As you (i.e. Tom, if someone else is grading) mentioned, all of the patches have solar panels in them, so the model gets lazy and learns to only predict “yes”. The sigmoid function at the end introduces a little bit of uncertainty, because the model knows in theory that there should be a “no” class, which is why we never get to 100% accuracy. The process of overfitting also shows in the loss consistently dropping in the training dataset, while rising in the validation dataset because it learns the wrong things (loss drop in training while loss rise in validation is a typical sign of overfitting).\n",
        "\n",
        "To fix that, I will create the “no” class and do data augmentation, because creating 2066 new patches would take me 3 days (educated guess).\n"
      ],
      "metadata": {
        "id": "JSWhKZBv6jy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6**: Exercise: using the materials taught in Lab 3 and given your answer to Q5, re-design your training data so that it is a robust training set for the detection of solar panels in S2 data. Your answer needs to include:\n",
        "*   A paragraph that explains what you have added to the train_data and any other steps taken in order to enhance the robustness of the training.\n",
        "*   A figure that demonstrates your newly added patches vs. the existing patches (remember that it needs to be publication quality).\n",
        "\n",
        "You do not need to create a 100% solution here. I am looking for you to demonstrate an understanding of the critical design flaw in this training set (particularly for a patch based, as opposed to segmentation, approach), and to show critical thinking in how you might fix it. This may include re-sampling the existing training data, including new training data, or changing the bands being used (or all of the above).\n",
        "\n"
      ],
      "metadata": {
        "id": "yIpojp9o_hof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A6:\n",
        "\n",
        "Alright, we have no “no solar panel” class. In order to create patches, I created a composite image over a predefined area of interest without clouds, like we did in the first few labs. Then I generated 500 random points (I regretted that number very quickly, but more later) and created 256x256 patches around them. I then sent a task to GEE to download all of these 500 patches to my drive. Well after half an hour I had around 100 patches, so I stopped the job. I then did data augmentation with these 100 patches. I rotated each one of them 3 times, and mirrored each rotation. That gave me 8x100=800 patches for my “no solar panel” class. that makes the dataset still be imbalanced, but I decided to be satisfied for the scope of this. Because, if the model would still only predict yes, it would now get to an accuracy of around 62%, and I think I can do better.\n",
        "\n",
        "Great, I’m actually very happy that you made us create this visualization, because with the same settings, the two patches look very different. I will just normalize the entire dataset to make everything look the same. I got the following output when comparing the two patch sets:\n",
        "\n",
        "It seems like I made a mistake when specifying the bands and the shape, or maybe these are the GEE defaults, I’m not sure. Fact is, this exercise shall just show our understanding and not deliver a perfect solution, so I won’t create new patches, but I’ll adjust both datasets to match eachother and become identical in their shape to be able to continue.\n",
        "I then unified the datasets and kept trac of their labels, then i augmented the “no” class with rotating and mirroring, creating 8 patches out of each single one, and then normalized the whole dataset to have the pixels have all the same brightness etc.\n",
        "Here is a quick visualisation after normalization showing that I’m trying but I’m not quite getting there yet… I tried to standardize using the average over the whole dataset.\n",
        "\n",
        "After trying some stuff out and it did not work, I decided to move on.\n"
      ],
      "metadata": {
        "id": "gaOkq0ea6zGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7**: Exercise: re-run the model with your new training data (remembering that I am not looking for a total solution), and further adjusted hyperparameters/RAM options. Write two paragraphs that:\n",
        "1. Sets out **all the changes** you have made and the reasoning for them.\n",
        "2. Asses the training and model results in terms of performance statistics, commenting on how/if your training data changes have made an impact.\n",
        "\n",
        "You may include figures to support your analysis if you wish, remembering to present them to publication standard if you do so."
      ],
      "metadata": {
        "id": "TpmT0KuvAphE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A7:\n",
        "\n",
        "Alright, I’m onto retraining the model with the new dataset. Here are the changes that I made:\n",
        "\n",
        "I increased the number of epochs from 5 to 25. More epochs means more opportunities to learn for the model, and 5 really is a ridiculous number, whereas 25 is also not way better. but more is more. I also increased the patience for the early stopper from 3 to 5 to give the model a bit more room (This turned out to be unnecessary because the training stagnated after 2 epochs already and had an accuracy of 100% !!!!!!!!!!!!!! :((((( ). Anyway, I added one more convolutional layer and increased the dense layer size to give the model a bit more capacity to learn. I ran the model a second time with an early stop waiting of back to 3 epochs, and it stopped after 3 epochs because the accuracy was again at 100%, which is very unsatisfying because obviously, I did something wrong along the way. I think the problem lies in the fact that I did not manage to normalize the dataset properly, and the patches from both classes have very significant brightness differences which makes the model overfit again, but for a different reason.\n"
      ],
      "metadata": {
        "id": "dLhduCbT67Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up GEE API\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='clara-geog761-tryout-1')"
      ],
      "metadata": {
        "id": "T4YkgwwliDRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import other libs\n",
        "import geemap\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "# Define area of interest\n",
        "aoi = ee.Geometry.Rectangle([175.3, -41, 175, -41.2])\n",
        "Map = geemap.Map(center=[-41.3, 174.75], zoom=10)\n",
        "Map.addLayer(aoi, {}, 'AOI')\n",
        "\n",
        "# Visualize on the map to check got it right... (always a good idea)\n",
        "Map"
      ],
      "metadata": {
        "id": "ixAyqVbHiWM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your filter Sentinel-2 imagery\n",
        "# A function that masks clouds in your S2 images via QA band\n",
        "def mask_s2_clouds(image):\n",
        "    qa = image.select('QA60')\n",
        "    cloudBitMask = 1 << 10\n",
        "    cirrusBitMask = 1 << 11\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(\n",
        "           qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "    return image.updateMask(mask).divide(10000).select(['B2', 'B3', 'B4', 'B8'])\n",
        "\n",
        "# Now build the clean collection with selected bands\n",
        "s2 = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "      .filterBounds(aoi) #This filters out all available images that overlap with my aoi\n",
        "      .filterDate('2020-01-01', '2020-12-31')\n",
        "      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
        "      .map(mask_s2_clouds)\n",
        "      .median() #<- think about this step and what it is doing to your image when you build your single composite from the image collection\n",
        "      .clip(aoi)) #This takes the final composite image that is an overlap of diferent images with different boundarie, all somehow inlcuding my aoi, and cutting it to only have my aoi"
      ],
      "metadata": {
        "id": "jI4nrK2wjRDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the visualisation and then once again check it has worked, stacking layers in a sensible order\n",
        "Map = geemap.Map(center=[-41.1, 175.1], zoom=11) #<- reset the map object to clear out other layers from earlier cells\n",
        "Map.addLayer(s2, {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3}, 'S2 RGB')\n",
        "Map.addLayer(aoi, {'color': 'red'}, 'AOI')\n",
        "Map"
      ],
      "metadata": {
        "id": "5djdLqJ1jVJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "B7rJpGYglTQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade earthengine-api"
      ],
      "metadata": {
        "id": "nn2_sfUEnUUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BANDS_TO_EXPORT = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']\n",
        "\n",
        "# Assume 's2' is your ee.ImageCollection and 'aoi' is your ee.Geometry\n",
        "NUM_PATCHES_TO_CREATE = 500\n",
        "PATCH_SIZE_METERS = 256 # Patch size in meters (e.g., 256x256 meters)\n",
        "\n",
        "EXPORT_FOLDER = 'GEE_Patches_No_Solar' # A folder in your Google Drive"
      ],
      "metadata": {
        "id": "MSDK_YHrmuq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Generate random points within the AOI\n",
        "random_points = ee.FeatureCollection.randomPoints(\n",
        "    region=aoi,\n",
        "    points=NUM_PATCHES_TO_CREATE,\n",
        "    seed=42 # Use a seed for reproducibility\n",
        ")\n",
        "\n",
        "# 3. Get the list of points from the server to the client (your Colab notebook)\n",
        "# .toList() brings the collection over so we can loop through it.\n",
        "points_list = random_points.toList(NUM_PATCHES_TO_CREATE)\n",
        "\n",
        "print(f\"Starting to create {points_list.size().getInfo()} export tasks...\")\n",
        "\n",
        "# 4. Loop through each point and create a separate export task for each one\n",
        "for i in range(NUM_PATCHES_TO_CREATE):\n",
        "    # Get a single point from the list\n",
        "    point = ee.Feature(points_list.get(i))\n",
        "\n",
        "    # Create the patch geometry on the server\n",
        "    patch_geometry = point.geometry().buffer(PATCH_SIZE_METERS / 2).bounds()\n",
        "\n",
        "    # Clip the source image to this patch's geometry\n",
        "    patch_image = s2.clip(patch_geometry)\n",
        "\n",
        "    # Define a unique name for each patch file\n",
        "    file_name = f'no_solar_patch_{i:03d}' # e.g., no_solar_patch_001\n",
        "\n",
        "    # Create and start the export task for this single patch\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=patch_image,\n",
        "        description=file_name,\n",
        "        folder=EXPORT_FOLDER,\n",
        "        fileNamePrefix=file_name,\n",
        "        scale=10,\n",
        "        fileFormat='GeoTIFF'\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "print(f\"\\nAll {NUM_PATCHES_TO_CREATE} export tasks have been started.\")\n",
        "print(f\"Check the 'Tasks' tab in the GEE Code Editor to monitor their progress.\")\n",
        "print(f\"The files will be saved in your Google Drive folder: '{EXPORT_FOLDER}'\")\n"
      ],
      "metadata": {
        "id": "_cmMjeTPm7KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DELETE TASK BECAUSE IT TAKES WAY TOO LONG FOR 500 PATCHES TO BE CREATED\n",
        "\n",
        "import ee\n",
        "\n",
        "# Make sure you have authenticated and initialized GEE\n",
        "# ee.Authenticate()\n",
        "# ee.Initialize()\n",
        "\n",
        "# 1. Get a list of all your current tasks from the GEE server\n",
        "tasks = ee.batch.Task.list()\n",
        "\n",
        "cancelled_count = 0\n",
        "print(\"Searching for tasks to cancel...\")\n",
        "\n",
        "# 2. Loop through the tasks\n",
        "for task in tasks:\n",
        "    # 3. Check if the task is part of your batch export and is still active\n",
        "    if 'no_solar_patch' in task.config['description'] and task.state in ['RUNNING', 'READY']:\n",
        "        # 4. If it matches, cancel it\n",
        "        task.cancel()\n",
        "        cancelled_count += 1\n",
        "        print(f\"Cancelling task: {task.config['description']}\")\n",
        "\n",
        "if cancelled_count > 0:\n",
        "    print(f\"\\nSuccessfully sent cancellation requests for {cancelled_count} tasks.\")\n",
        "else:\n",
        "    print(\"\\nNo active 'no_solar_patch' tasks found to cancel.\")"
      ],
      "metadata": {
        "id": "IV-c-eBJzWqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING VISUALIZATION OF EXISTING PATCH VS CREATED PATCH BY MYSELF\n",
        "\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access the files\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception as e:\n",
        "    print(f\"Could not mount drive: {e}\")\n",
        "\n",
        "# --- File Paths ---\n",
        "# Path to your original patch with a solar panel\n",
        "old_patch_path = \"/content/train_data/s2_image/train_s2_image_1.tif\"\n",
        "\n",
        "# Path to one of your newly created patches without a solar panel\n",
        "new_patch_path = \"/content/drive/MyDrive/GEE_Patches_No_Solar/no_solar_patch_001.tif\"\n",
        "\n",
        "# --- Visualization Function ---\n",
        "def create_comparison_figure(path1, path2):\n",
        "    \"\"\"\n",
        "    Reads two multi-band GeoTIFFs and displays them side-by-side\n",
        "    as true-color images.\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # --- Process and display the first image ---\n",
        "    try:\n",
        "        with rasterio.open(path1) as src:\n",
        "            # Read true-color bands (B4=Red, B3=Green, B2=Blue)\n",
        "            rgb1 = np.dstack((src.read(4), src.read(3), src.read(2)))\n",
        "            # Contrast stretch for better visualization\n",
        "            p2, p98 = np.percentile(rgb1, (2, 98))\n",
        "            rgb1_stretched = np.clip((rgb1 - p2) * (255.0 / (p98 - p2)), 0, 255).astype(np.uint8)\n",
        "            ax1.imshow(rgb1_stretched)\n",
        "            ax1.set_title(\"Original Patch ('Yes' Class)\", fontsize=12)\n",
        "    except Exception as e:\n",
        "        ax1.text(0.5, 0.5, f\"Could not load:\\n{os.path.basename(path1)}\", ha='center', va='center')\n",
        "        print(f\"Error loading {path1}: {e}\")\n",
        "\n",
        "    # --- Process and display the second image ---\n",
        "    try:\n",
        "        with rasterio.open(path2) as src:\n",
        "            rgb2 = np.dstack((src.read(4), src.read(3), src.read(2)))\n",
        "            p2, p98 = np.percentile(rgb2, (2, 98))\n",
        "            rgb2_stretched = np.clip((rgb2 - p2) * (255.0 / (p98 - p2)), 0, 255).astype(np.uint8)\n",
        "            ax2.imshow(rgb2_stretched)\n",
        "            ax2.set_title(\"Generated Patch ('No' Class)\", fontsize=12)\n",
        "    except Exception as e:\n",
        "        ax2.text(0.5, 0.5, f\"Could not load:\\n{os.path.basename(path2)}\", ha='center', va='center')\n",
        "        print(f\"Error loading {path2}: {e}\")\n",
        "\n",
        "    # --- Final Figure Details ---\n",
        "    for ax in [ax1, ax2]:\n",
        "        ax.axis('off')\n",
        "\n",
        "    caption = \"Side-by-side comparison of an original training patch containing solar panels (left) \\nand a randomly generated patch for the 'no solar panel' class (right).\"\n",
        "    fig.suptitle(caption, y=0.08, fontsize=14)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.1, 1, 1]) # Adjust layout to make room for caption\n",
        "    plt.show()\n",
        "\n",
        "# --- Run the visualization ---\n",
        "create_comparison_figure(old_patch_path, new_patch_path)"
      ],
      "metadata": {
        "id": "6oKlemkQy-XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PATCH COMPARISON BETWEEN ORIGINAL TRAINING DATA SET AND MY GENERATED DATASET\n",
        "\n",
        "import rasterio\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "# 1. SET THIS to the path of your ORIGINAL 'yes' solar panel patches\n",
        "YES_PATCH_DIR = \"/content/train_data/s2_image/\"\n",
        "\n",
        "# 2. SET THIS to the path of your GENERATED 'no' solar panel patches\n",
        "#    (The folder you unzipped after running the augmentation)\n",
        "NO_PATCH_DIR = \"/content/drive/MyDrive/GEE_Patches_No_Solar/\"\n",
        "\n",
        "\n",
        "def inspect_single_patch(patch_path):\n",
        "    \"\"\"\n",
        "    Opens a single GeoTIFF and prints its key properties.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with rasterio.open(patch_path) as src:\n",
        "            print(f\"File: {os.path.basename(patch_path)}\")\n",
        "            print(f\"  - Shape (bands, height, width): ({src.count}, {src.height}, {src.width})\")\n",
        "            print(f\"  - Band Count: {src.count}\")\n",
        "            print(f\"  - Data Type: {src.dtypes[0]}\")\n",
        "            print(\"-\" * 40)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not inspect file: {patch_path}\")\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "\n",
        "# --- Run the Comparison ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*50)\n",
        "    print(\"     SINGLE PATCH COMPARISON REPORT\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    # --- Inspect one 'YES' patch ---\n",
        "    print(\"--- Inspecting one 'YES' Patch (Original Dataset) ---\\n\")\n",
        "    yes_files = glob.glob(os.path.join(YES_PATCH_DIR, '*.tif'))\n",
        "    if yes_files:\n",
        "        inspect_single_patch(yes_files[0])\n",
        "    else:\n",
        "        print(f\"No .tif files found in '{YES_PATCH_DIR}'\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # --- Inspect one 'NO' patch ---\n",
        "    print(\"\\n--- Inspecting one 'NO' Patch (Generated Dataset) ---\\n\")\n",
        "    no_files = glob.glob(os.path.join(NO_PATCH_DIR, '*.tif'))\n",
        "    if no_files:\n",
        "        inspect_single_patch(no_files[0])\n",
        "    else:\n",
        "        print(f\"No .tif files found in '{NO_PATCH_DIR}'\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    print(\"\\nFor the datasets to be compatible, their properties should be identical.\")"
      ],
      "metadata": {
        "id": "bEm49-Xsp8SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATEN ANGLEICHUNG, I NEED TO ADJUST BOTH DATASET TO BECOME IDENTICAL IN SHAPE\n",
        "\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- Configuration ---\n",
        "# 1. Path to your ORIGINAL 'yes' solar panel patches (12 bands)\n",
        "YES_PATCH_DIR = \"/content/train_data/s2_image/\"\n",
        "\n",
        "# 2. Path to your GENERATED 'no' solar panel patches (4 bands, wrong size)\n",
        "NO_PATCH_DIR = \"/content/drive/MyDrive/GEE_Patches_No_Solar/\" # Using the un-augmented GEE patches\n",
        "\n",
        "# 3. Path for the NEW, UNIFIED dataset. This script will create it.\n",
        "UNIFIED_OUTPUT_DIR = \"/content/Unified_Dataset/\"\n",
        "\n",
        "# 4. Path for the final CSV manifest file.\n",
        "FINAL_MANIFEST_PATH = \"/content/unified_dataset_labels.csv\"\n",
        "\n",
        "\n",
        "def get_band_indices_to_keep(sample_yes_path, sample_no_path):\n",
        "    \"\"\"\n",
        "    Inspects sample files to dynamically determine which band indices to keep.\n",
        "    If band descriptions are not present, it falls back to a safe default.\n",
        "    \"\"\"\n",
        "    print(\"--- Checking Band Information ---\")\n",
        "    try:\n",
        "        with rasterio.open(sample_no_path) as src_no:\n",
        "            target_bands = src_no.descriptions\n",
        "            if not all(target_bands):\n",
        "                raise ValueError(\"No band descriptions found in the 'no' patch.\")\n",
        "\n",
        "        with rasterio.open(sample_yes_path) as src_yes:\n",
        "            source_bands = src_yes.descriptions\n",
        "            if not all(source_bands):\n",
        "                raise ValueError(\"No band descriptions found in the 'yes' patch.\")\n",
        "\n",
        "        print(f\"  - Detected target bands from 'no' patch: {target_bands}\")\n",
        "        print(f\"  - Found source bands from 'yes' patch: {source_bands}\")\n",
        "\n",
        "        # Find the 0-based index for each target band in the source list\n",
        "        indices = [source_bands.index(band) for band in target_bands]\n",
        "        print(f\"  - Dynamically determined band indices to keep: {indices}\")\n",
        "        return indices\n",
        "\n",
        "    except (ValueError, AttributeError, IndexError) as e:\n",
        "        print(f\"  - Warning: Could not dynamically determine bands. Reason: {e}\")\n",
        "        print(\"  - Falling back to default Sentinel-2 bands (B2, B3, B4, NIR).\")\n",
        "        # Default 0-based indices for B2, B3, B4, B8\n",
        "        return [1, 2, 3, 7]\n",
        "\n",
        "\n",
        "def unify_datasets(yes_dir, no_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Unifies two mismatched patch datasets by clipping bands and cropping dimensions.\n",
        "    \"\"\"\n",
        "    # Create a clean output directory\n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "    print(f\"Created clean output directory: {output_dir}\")\n",
        "\n",
        "    all_file_info = []\n",
        "\n",
        "    # Get file lists\n",
        "    yes_files = glob.glob(os.path.join(yes_dir, '*.tif'))\n",
        "    no_files = glob.glob(os.path.join(no_dir, '*.tif'))\n",
        "\n",
        "    if not yes_files or not no_files:\n",
        "        print(\"\\nError: Could not find .tif files in one or both directories. Aborting.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --- Dynamically determine which bands to keep ---\n",
        "    BANDS_TO_KEEP = get_band_indices_to_keep(yes_files[0], no_files[0])\n",
        "\n",
        "    # --- 1. Process 'YES' patches (Clip bands) ---\n",
        "    print(f\"\\nProcessing {len(yes_files)} 'yes' patches (clipping to {len(BANDS_TO_KEEP)} bands)...\")\n",
        "\n",
        "    for path in yes_files:\n",
        "        with rasterio.open(path) as src:\n",
        "            if src.count < max(BANDS_TO_KEEP) + 1:\n",
        "                print(f\"  - Warning: Skipping {os.path.basename(path)}, not enough bands.\")\n",
        "                continue\n",
        "\n",
        "            all_bands_data = src.read()\n",
        "            clipped_data = all_bands_data[BANDS_TO_KEEP, :, :]\n",
        "\n",
        "            profile = src.profile\n",
        "            profile.update(count=len(BANDS_TO_KEEP), driver='GTiff', dtype=clipped_data.dtype)\n",
        "\n",
        "            new_filename = os.path.basename(path)\n",
        "            new_path = os.path.join(output_dir, new_filename)\n",
        "            with rasterio.open(new_path, 'w', **profile) as dst:\n",
        "                dst.write(clipped_data)\n",
        "\n",
        "            all_file_info.append({'filepath': new_path, 'label': 1})\n",
        "\n",
        "    # --- 2. Process 'NO' patches (Center crop) ---\n",
        "    print(f\"\\nProcessing {len(no_files)} 'no' patches (cropping to 23x23)...\")\n",
        "\n",
        "    TARGET_HEIGHT, TARGET_WIDTH = 23, 23\n",
        "\n",
        "    for path in no_files:\n",
        "        with rasterio.open(path) as src:\n",
        "            data = src.read()\n",
        "\n",
        "            h, w = src.height, src.width\n",
        "            top = (h - TARGET_HEIGHT) // 2\n",
        "            left = (w - TARGET_WIDTH) // 2\n",
        "\n",
        "            cropped_data = data[:, top:top + TARGET_HEIGHT, left:left + TARGET_WIDTH]\n",
        "\n",
        "            profile = src.profile\n",
        "            profile.update(height=TARGET_HEIGHT, width=TARGET_WIDTH, dtype=cropped_data.dtype)\n",
        "\n",
        "            new_filename = os.path.basename(path)\n",
        "            new_path = os.path.join(output_dir, new_filename)\n",
        "            with rasterio.open(new_path, 'w', **profile) as dst:\n",
        "                dst.write(cropped_data)\n",
        "\n",
        "            all_file_info.append({'filepath': new_path, 'label': 0})\n",
        "\n",
        "    print(\"\\nDataset unification complete.\")\n",
        "    return pd.DataFrame(all_file_info)\n",
        "\n",
        "# --- Run the Unification ---\n",
        "if __name__ == \"__main__\":\n",
        "    manifest_df = unify_datasets(YES_PATCH_DIR, NO_PATCH_DIR, UNIFIED_OUTPUT_DIR)\n",
        "\n",
        "    if not manifest_df.empty:\n",
        "        manifest_df.to_csv(FINAL_MANIFEST_PATH, index=False)\n",
        "        print(f\"\\nFinal manifest file saved to: {FINAL_MANIFEST_PATH}\")\n",
        "        print(f\"Total unified patches: {len(manifest_df)}\")\n",
        "        print(\"\\nYour dataset is now unified and ready for normalization or training!\")\n",
        "    else:\n",
        "        print(\"\\nNo files were processed. The final manifest was not created.\")"
      ],
      "metadata": {
        "id": "EIPJDX7u-OCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET VERYFIER\n",
        "\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- Configuration ---\n",
        "# 1. Path to your ORIGINAL 'yes' solar panel patches (inconsistent sizes)\n",
        "YES_PATCH_DIR = \"/content/train_data/s2_image/\"\n",
        "\n",
        "# 2. Path to your GENERATED 'no' solar panel patches (4 bands, wrong size)\n",
        "NO_PATCH_DIR = \"/content/drive/MyDrive/GEE_Patches_No_Solar/\"\n",
        "\n",
        "# 3. Path for the FINAL, UNIFIED dataset. This script will create it.\n",
        "UNIFIED_OUTPUT_DIR = \"/content/Unified_Dataset_Final/\"\n",
        "\n",
        "# 4. Path for the final CSV manifest file.\n",
        "FINAL_MANIFEST_PATH = \"/content/unified_dataset_labels_final.csv\"\n",
        "\n",
        "# 5. Define the one true shape for all patches\n",
        "TARGET_BANDS = 4\n",
        "TARGET_HEIGHT = 23\n",
        "TARGET_WIDTH = 23\n",
        "\n",
        "\n",
        "def get_band_indices_to_keep(sample_yes_path, sample_no_path):\n",
        "    \"\"\"\n",
        "    Inspects sample files to dynamically determine which band indices to keep.\n",
        "    \"\"\"\n",
        "    print(\"--- Checking Band Information ---\")\n",
        "    try:\n",
        "        with rasterio.open(sample_no_path) as src_no:\n",
        "            target_bands = src_no.descriptions\n",
        "            if not all(target_bands): raise ValueError(\"No band descriptions in 'no' patch.\")\n",
        "        with rasterio.open(sample_yes_path) as src_yes:\n",
        "            source_bands = src_yes.descriptions\n",
        "            if not all(source_bands): raise ValueError(\"No band descriptions in 'yes' patch.\")\n",
        "\n",
        "        print(f\"  - Target bands from 'no' patch: {target_bands}\")\n",
        "        indices = [source_bands.index(band) for band in target_bands]\n",
        "        indices_1based = [i + 1 for i in indices]\n",
        "        print(f\"  - Dynamically determined band indices to keep: {indices_1based}\")\n",
        "        return indices_1based\n",
        "    except Exception as e:\n",
        "        print(f\"  - Warning: Could not dynamically determine bands. Reason: {e}\")\n",
        "        print(\"  - Falling back to default Sentinel-2 bands (B2, B3, B4, B8).\")\n",
        "        return [2, 3, 4, 8]\n",
        "\n",
        "\n",
        "def center_crop_data(data, target_height, target_width):\n",
        "    \"\"\"\n",
        "    Crops a numpy array (bands, height, width) from the center.\n",
        "    \"\"\"\n",
        "    _ , h, w = data.shape\n",
        "    start_x = w // 2 - target_width // 2\n",
        "    start_y = h // 2 - target_height // 2\n",
        "    return data[:, start_y:start_y + target_height, start_x:start_x + target_width]\n",
        "\n",
        "\n",
        "def unify_datasets_final(yes_dir, no_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Unifies two mismatched datasets by forcing all patches to a target\n",
        "    dimension using band clipping and center cropping.\n",
        "    \"\"\"\n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "    print(f\"Created clean output directory: {output_dir}\")\n",
        "\n",
        "    all_file_info = []\n",
        "    yes_files = glob.glob(os.path.join(yes_dir, '*.tif'))\n",
        "    no_files = glob.glob(os.path.join(no_dir, '*.tif'))\n",
        "\n",
        "    if not yes_files or not no_files:\n",
        "        print(\"\\nError: Could not find .tif files. Please check YES_PATCH_DIR and NO_PATCH_DIR.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    BANDS_TO_KEEP = get_band_indices_to_keep(yes_files[0], no_files[0])\n",
        "\n",
        "    # --- 1. Process 'YES' patches (Clip bands AND Center Crop) ---\n",
        "    print(f\"\\nProcessing {len(yes_files)} 'yes' patches (clipping bands and cropping to 23x23)...\")\n",
        "\n",
        "    for path in yes_files:\n",
        "        with rasterio.open(path) as src:\n",
        "            profile = src.profile\n",
        "            # Read only the bands we need\n",
        "            clipped_data = src.read(BANDS_TO_KEEP)\n",
        "\n",
        "            # Perform a center crop on the clipped data\n",
        "            cropped_data = center_crop_data(clipped_data, TARGET_HEIGHT, TARGET_WIDTH)\n",
        "\n",
        "            # Check if cropping was successful\n",
        "            if cropped_data.shape != (TARGET_BANDS, TARGET_HEIGHT, TARGET_WIDTH):\n",
        "                print(f\"  - Warning: Skipping {os.path.basename(path)} due to incompatible size for cropping.\")\n",
        "                continue\n",
        "\n",
        "            profile.update(count=TARGET_BANDS, height=TARGET_HEIGHT, width=TARGET_WIDTH, dtype=cropped_data.dtype)\n",
        "\n",
        "            new_path = os.path.join(output_dir, os.path.basename(path))\n",
        "            with rasterio.open(new_path, 'w', **profile) as dst:\n",
        "                dst.write(cropped_data)\n",
        "\n",
        "            all_file_info.append({'filepath': new_path, 'label': 1})\n",
        "\n",
        "    # --- 2. Process 'NO' patches (Center Crop only) ---\n",
        "    print(f\"\\nProcessing {len(no_files)} 'no' patches (cropping to 23x23)...\")\n",
        "\n",
        "    for path in no_files:\n",
        "        with rasterio.open(path) as src:\n",
        "            profile = src.profile\n",
        "            # Read all 4 bands\n",
        "            data = src.read()\n",
        "\n",
        "            # Perform a center crop\n",
        "            cropped_data = center_crop_data(data, TARGET_HEIGHT, TARGET_WIDTH)\n",
        "\n",
        "            if cropped_data.shape != (TARGET_BANDS, TARGET_HEIGHT, TARGET_WIDTH):\n",
        "                print(f\"  - Warning: Skipping {os.path.basename(path)} due to incompatible size for cropping.\")\n",
        "                continue\n",
        "\n",
        "            profile.update(height=TARGET_HEIGHT, width=TARGET_WIDTH, dtype=cropped_data.dtype)\n",
        "\n",
        "            new_path = os.path.join(output_dir, os.path.basename(path))\n",
        "            with rasterio.open(new_path, 'w', **profile) as dst:\n",
        "                dst.write(cropped_data)\n",
        "\n",
        "            all_file_info.append({'filepath': new_path, 'label': 0})\n",
        "\n",
        "    print(\"\\nDataset unification complete.\")\n",
        "    return pd.DataFrame(all_file_info)\n",
        "\n",
        "# --- Run the Unification ---\n",
        "if __name__ == \"__main__\":\n",
        "    manifest_df = unify_datasets_final(YES_PATCH_DIR, NO_PATCH_DIR, UNIFIED_OUTPUT_DIR)\n",
        "\n",
        "    if not manifest_df.empty:\n",
        "        manifest_df.to_csv(FINAL_MANIFEST_PATH, index=False)\n",
        "        print(f\"\\nFinal manifest file saved to: {FINAL_MANIFEST_PATH}\")\n",
        "        print(f\"Total unified patches: {len(manifest_df)}\")\n",
        "    else:\n",
        "        print(\"\\nNo files were processed.\")\n"
      ],
      "metadata": {
        "id": "SfxWM3Ud-_fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA AUGMENTATION OF THE NO CLASS IN THE ALREADY UNIFIED AND CROPPED DATASET\n",
        "\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "# 1. Path to your UNIFIED dataset (the output from the previous step)\n",
        "UNIFIED_DATA_DIR = \"/content/Unified_Dataset_Final/\"\n",
        "\n",
        "# 2. Path for the FINAL dataset CSV manifest (created by the unifier script)\n",
        "MANIFEST_PATH = \"/content/unified_dataset_labels_final.csv\"\n",
        "\n",
        "# 3. Path for the NEW augmented 'no' patches. This script will create it.\n",
        "AUGMENTED_OUTPUT_DIR = \"/content/Augmented_Unified_No_Solar/\"\n",
        "\n",
        "# 4. Path for the FINAL CSV manifest that includes the augmented files.\n",
        "FINAL_AUGMENTED_MANIFEST_PATH = \"/content/final_augmented_dataset_labels.csv\"\n",
        "\n",
        "\n",
        "def augment_unified_patches(unified_dir, manifest_path, output_dir):\n",
        "    \"\"\"\n",
        "    Reads unified 'no' patches, creates 8 augmented versions of each,\n",
        "    and saves them to a new directory. Then creates a new manifest file\n",
        "    that includes both the 'yes' patches and the new augmented 'no' patches.\n",
        "    \"\"\"\n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "    print(f\"Created clean output directory: {output_dir}\")\n",
        "\n",
        "    try:\n",
        "        manifest_df = pd.read_csv(manifest_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Manifest file not found at {manifest_path}. Aborting.\")\n",
        "        return\n",
        "\n",
        "    # Separate the 'yes' and 'no' patches from the manifest\n",
        "    yes_patches_df = manifest_df[manifest_df['label'] == 1]\n",
        "    no_patches_df = manifest_df[manifest_df['label'] == 0]\n",
        "\n",
        "    no_files_to_augment = no_patches_df['filepath'].tolist()\n",
        "\n",
        "    print(f\"Found {len(no_files_to_augment)} unified 'no' patches to augment...\")\n",
        "\n",
        "    new_augmented_rows = []\n",
        "\n",
        "    for path in tqdm(no_files_to_augment, desc=\"Augmenting 'No' Patches\"):\n",
        "        try:\n",
        "            with rasterio.open(path) as src:\n",
        "                data = src.read()\n",
        "                profile = src.profile\n",
        "\n",
        "                base_filename = os.path.splitext(os.path.basename(path))[0]\n",
        "\n",
        "                # Define the 8 transformations\n",
        "                transforms = {\n",
        "                    'orig': data,\n",
        "                    'rot90': np.rot90(data, 1, axes=(1, 2)),\n",
        "                    'rot180': np.rot90(data, 2, axes=(1, 2)),\n",
        "                    'rot270': np.rot90(data, 3, axes=(1, 2))\n",
        "                }\n",
        "\n",
        "                # Apply transformations and save\n",
        "                for name, transformed_data in transforms.items():\n",
        "                    # Save the rotated version\n",
        "                    out_path = os.path.join(output_dir, f\"{base_filename}_{name}.tif\")\n",
        "                    with rasterio.open(out_path, 'w', **profile) as dst:\n",
        "                        dst.write(transformed_data)\n",
        "                    new_augmented_rows.append({'filepath': out_path, 'label': 0})\n",
        "\n",
        "                    # Save the flipped version of the rotation\n",
        "                    flipped_data = np.flip(transformed_data, axis=2)\n",
        "                    out_path_flipped = os.path.join(output_dir, f\"{base_filename}_{name}_flip.tif\")\n",
        "                    with rasterio.open(out_path_flipped, 'w', **profile) as dst:\n",
        "                        dst.write(flipped_data)\n",
        "                    new_augmented_rows.append({'filepath': out_path_flipped, 'label': 0})\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  - Warning: Could not process {os.path.basename(path)}. Skipping. Error: {e}\")\n",
        "\n",
        "    augmented_no_df = pd.DataFrame(new_augmented_rows)\n",
        "\n",
        "    # Combine the original 'yes' patches with the new augmented 'no' patches\n",
        "    final_df = pd.concat([yes_patches_df, augmented_no_df], ignore_index=True)\n",
        "\n",
        "    print(f\"\\nAugmentation complete.\")\n",
        "    print(f\"  - Original 'yes' patches: {len(yes_patches_df)}\")\n",
        "    print(f\"  - New augmented 'no' patches: {len(augmented_no_df)}\")\n",
        "    print(f\"  - Total patches in new dataset: {len(final_df)}\")\n",
        "\n",
        "    return final_df\n",
        "\n",
        "# --- Run the Augmentation ---\n",
        "if __name__ == \"__main__\":\n",
        "    final_manifest = augment_unified_patches(UNIFIED_DATA_DIR, MANIFEST_PATH, AUGMENTED_OUTPUT_DIR)\n",
        "\n",
        "    if final_manifest is not None and not final_manifest.empty:\n",
        "        final_manifest.to_csv(FINAL_AUGMENTED_MANIFEST_PATH, index=False)\n",
        "        print(f\"\\nFinal augmented manifest file saved to: {FINAL_AUGMENTED_MANIFEST_PATH}\")\n"
      ],
      "metadata": {
        "id": "ez7C4METCSCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NORMALIZE ENTIRE DATASET\n",
        "# This normlization DOES NOT WORK, go see the post-normalization verification for some funny end results.\n",
        "# But oh well, at least I know how to create patches and am halfway to being able to create a usable dataset. It's definitely not usable yet.\n",
        "\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "# 1. Path to the FINAL CSV manifest from the augmentation step.\n",
        "AUGMENTED_MANIFEST_PATH = \"/content/final_augmented_dataset_labels.csv\"\n",
        "\n",
        "# 2. Directory where the unified TIFF patches are stored.\n",
        "#    This is needed to read the files for calculating statistics.\n",
        "UNIFIED_PATCH_DIR = \"/content/Unified_Dataset_Final/\"\n",
        "\n",
        "# 3. Directory to save the final, normalized dataset (as .npy files).\n",
        "OUTPUT_NORMALIZED_DIR = \"/content/Final_Normalized_Dataset/\"\n",
        "\n",
        "# 4. Path to save the final CSV manifest pointing to the .npy files.\n",
        "FINAL_NORMALIZED_MANIFEST_PATH = \"/content/final_normalized_dataset_manifest.csv\"\n",
        "\n",
        "# 5. Path to save the statistics file.\n",
        "STATS_FILE_PATH = \"/content/dataset_stats.npz\"\n",
        "\n",
        "\n",
        "def calculate_statistics_from_all(base_dir, all_files):\n",
        "    \"\"\"\n",
        "    Calculates the mean and standard deviation for each band from the\n",
        "    ENTIRE dataset.\n",
        "    \"\"\"\n",
        "    print(f\"Calculating global statistics from {len(all_files)} patches...\")\n",
        "\n",
        "    band_pixel_values = [[] for _ in range(4)] # Assuming 4 bands\n",
        "\n",
        "    for file_path in tqdm(all_files, desc=\"Calculating Stats\"):\n",
        "        try:\n",
        "            # The manifest contains full paths, so we use them directly\n",
        "            with rasterio.open(file_path) as src:\n",
        "                data = src.read()\n",
        "                for i in range(data.shape[0]):\n",
        "                    band_pixel_values[i].extend(data[i].flatten())\n",
        "        except Exception as e:\n",
        "            print(f\"  - Warning: Could not read {os.path.basename(file_path)} for stats. Skipping. Error: {e}\")\n",
        "\n",
        "    mean_per_band = np.array([np.mean(pixels) for pixels in band_pixel_values])\n",
        "    std_per_band = np.array([np.std(pixels) for pixels in band_pixel_values])\n",
        "\n",
        "    mean = mean_per_band[:, np.newaxis, np.newaxis]\n",
        "    std = std_per_band[:, np.newaxis, np.newaxis]\n",
        "\n",
        "    std[std == 0] = 1 # Avoid division by zero\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "def normalize_dataset(df, output_dir, mean, std_dev):\n",
        "    \"\"\"\n",
        "    Normalizes all patches in the dataframe using pre-calculated stats\n",
        "    and saves them as .npy files.\n",
        "    \"\"\"\n",
        "    new_rows = []\n",
        "\n",
        "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Normalizing Patches\"):\n",
        "        patch_path = row['filepath']\n",
        "        label = row['label']\n",
        "\n",
        "        try:\n",
        "            # We need to read from the original unified/augmented TIFFs, not the final .npy files\n",
        "            with rasterio.open(patch_path) as src:\n",
        "                data = src.read().astype(np.float32)\n",
        "\n",
        "                normalized_data = (data - mean) / std_dev\n",
        "\n",
        "                base_filename = os.path.splitext(os.path.basename(patch_path))[0]\n",
        "                new_filename = f\"{base_filename}_norm.npy\"\n",
        "                new_filepath = os.path.join(output_dir, new_filename)\n",
        "\n",
        "                np.save(new_filepath, normalized_data)\n",
        "\n",
        "                new_rows.append({'filepath': new_filepath, 'label': label})\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  - Warning: Could not normalize {os.path.basename(patch_path)}. Skipping. Error: {e}\")\n",
        "\n",
        "    return pd.DataFrame(new_rows)\n",
        "\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    if os.path.exists(OUTPUT_NORMALIZED_DIR):\n",
        "        shutil.rmtree(OUTPUT_NORMALIZED_DIR)\n",
        "    os.makedirs(OUTPUT_NORMALIZED_DIR)\n",
        "    print(f\"Created clean output directory: {OUTPUT_NORMALIZED_DIR}\")\n",
        "\n",
        "    try:\n",
        "        manifest_df = pd.read_csv(AUGMENTED_MANIFEST_PATH)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ ERROR: Augmented manifest file not found at {AUGMENTED_MANIFEST_PATH}. Aborting.\")\n",
        "        exit()\n",
        "\n",
        "    # --- 1. Calculate Statistics from the ENTIRE augmented dataset ---\n",
        "    # Get a list of all .tif file paths from the manifest\n",
        "    all_tiff_files = manifest_df['filepath'].tolist()\n",
        "\n",
        "    # Pass the full list to the statistics function\n",
        "    mean, std = calculate_statistics_from_all(UNIFIED_PATCH_DIR, all_tiff_files)\n",
        "\n",
        "    print(\"\\nGlobal statistics calculation complete.\")\n",
        "    np.savez(STATS_FILE_PATH, mean=mean, std=std)\n",
        "    print(f\"Statistics saved to {STATS_FILE_PATH}\")\n",
        "\n",
        "    # --- 2. Normalize the ENTIRE dataset using these global stats ---\n",
        "    final_normalized_df = normalize_dataset(manifest_df, OUTPUT_NORMALIZED_DIR, mean, std)\n",
        "\n",
        "    # --- 3. Save the FINAL normalized manifest CSV ---\n",
        "    if not final_normalized_df.empty:\n",
        "        final_normalized_df.to_csv(FINAL_NORMALIZED_MANIFEST_PATH, index=False)\n",
        "        print(f\"\\n✅ SUCCESS: Normalization complete.\")\n",
        "        print(f\"Final model-ready manifest saved to: {FINAL_NORMALIZED_MANIFEST_PATH}\")\n",
        "    else:\n",
        "        print(\"\\n❌ FAILED: No patches were normalized. Check for warnings.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "J0rwf4Hs8o1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# post normalization verification step\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Configuration ---\n",
        "# 1. Path to the AUGMENTED (but not normalized) manifest CSV. THIS PATH HAS BEEN UPDATED.\n",
        "AUGMENTED_MANIFEST_PATH = \"/content/final_augmented_dataset_labels.csv\"\n",
        "\n",
        "# 2. Path to the FINAL NORMALIZED manifest CSV.\n",
        "NORMALIZED_MANIFEST_PATH = \"/content/final_normalized_dataset_manifest.csv\"\n",
        "\n",
        "# 3. Path to the saved statistics file.\n",
        "STATS_FILE_PATH = \"/content/dataset_stats.npz\"\n",
        "\n",
        "\n",
        "def find_original_base_name(augmented_filename):\n",
        "    \"\"\"\n",
        "    Strips all augmentation and normalization suffixes to find the\n",
        "    original base filename from the unified dataset.\n",
        "    e.g., 'no_solar_patch_040_rot180_flip_norm.npy' -> 'no_solar_patch_040.tif'\n",
        "    \"\"\"\n",
        "    base = augmented_filename.replace('_norm.npy', '')\n",
        "    suffixes = ['_orig_flip', '_rot90_flip', '_rot180_flip', '_rot270_flip',\n",
        "                '_orig', '_rot90', '_rot180', '_rot270', '_flip']\n",
        "    for suffix in suffixes:\n",
        "        if base.endswith(suffix):\n",
        "            return base[:-len(suffix)] + '.tif'\n",
        "    return base + '.tif'\n",
        "\n",
        "\n",
        "def verify_normalization(augmented_manifest_path, normalized_manifest_path, stats_path):\n",
        "    \"\"\"\n",
        "    Verifies the normalization by checking statistics and visualizing a before-and-after comparison.\n",
        "    \"\"\"\n",
        "    print(\"==================================================\")\n",
        "    print(\"      POST-NORMALIZATION VERIFICATION SCRIPT\")\n",
        "    print(\"==================================================\")\n",
        "\n",
        "    try:\n",
        "        augmented_df = pd.read_csv(augmented_manifest_path)\n",
        "        normalized_df = pd.read_csv(normalized_manifest_path)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"❌ FAILED: Could not find a required file. Error: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"Loaded all necessary files successfully.\\n\")\n",
        "    print(\"--- Statistical Verification ---\")\n",
        "    print(\"Checking if the mean of normalized patches is ~0.0 and std dev is ~1.0...\")\n",
        "\n",
        "    # Select one random 'yes' and one random 'no' patch from the normalized set\n",
        "    yes_sample_norm = normalized_df[normalized_df['label'] == 1].sample(1).iloc[0]\n",
        "    no_sample_norm = normalized_df[normalized_df['label'] == 0].sample(1).iloc[0]\n",
        "\n",
        "    # --- Verify the 'yes' sample ---\n",
        "    yes_data_norm = np.load(yes_sample_norm['filepath'])\n",
        "    print(f\"\\n- YES Patch ({os.path.basename(yes_sample_norm['filepath'])}):\")\n",
        "    print(f\"  - Mean: {np.mean(yes_data_norm):.4f} (should be close to 0)\")\n",
        "    print(f\"  - Std Dev: {np.std(yes_data_norm):.4f} (should be close to 1)\")\n",
        "\n",
        "    # --- Verify the 'no' sample ---\n",
        "    no_data_norm = np.load(no_sample_norm['filepath'])\n",
        "    print(f\"\\n- NO Patch ({os.path.basename(no_sample_norm['filepath'])}):\")\n",
        "    print(f\"  - Mean: {np.mean(no_data_norm):.4f} (should be close to 0)\")\n",
        "    print(f\"  - Std Dev: {np.std(no_data_norm):.4f} (should be close to 1)\")\n",
        "\n",
        "    print(\"\\n--- Visual Verification ---\")\n",
        "    print(\"Displaying a before-and-after comparison...\")\n",
        "\n",
        "    # Get the base filename of the normalized samples, without the suffix or directory\n",
        "    yes_filename_before = os.path.basename(yes_sample_norm['filepath']).replace('_norm.npy', '.tif')\n",
        "    no_filename_before = os.path.basename(no_sample_norm['filepath']).replace('_norm.npy', '.tif')\n",
        "\n",
        "    # Find the full paths in the augmented dataframe by searching for the base filename\n",
        "    yes_path_before_series = augmented_df[augmented_df['filepath'].str.endswith(yes_filename_before, na=False)]\n",
        "    no_path_before_series = augmented_df[augmented_df['filepath'].str.endswith(no_filename_before, na=False)]\n",
        "\n",
        "    # Check that we found a match before trying to access it\n",
        "    if yes_path_before_series.empty or no_path_before_series.empty:\n",
        "        print(f\"\\n❌ FAILED: Could not find the original 'before' patch for visualization.\")\n",
        "        print(f\"Searched for filenames ending with '{yes_filename_before}' and '{no_filename_before}'.\")\n",
        "        return\n",
        "\n",
        "    yes_path_before = yes_path_before_series['filepath'].iloc[0]\n",
        "    no_path_before = no_path_before_series['filepath'].iloc[0]\n",
        "\n",
        "    with rasterio.open(yes_path_before) as src:\n",
        "        yes_data_before = src.read()\n",
        "    with rasterio.open(no_path_before) as src:\n",
        "        no_data_before = src.read()\n",
        "\n",
        "    # Create a 2x2 plot\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "\n",
        "    def visualize_rgb(data, ax, title):\n",
        "        rgb = data[:3, :, :].transpose(1, 2, 0)\n",
        "        p2, p98 = np.percentile(rgb, (2, 98))\n",
        "        rgb_stretched = np.clip((rgb - p2) / (p98 - p2), 0, 1)\n",
        "        ax.imshow(rgb_stretched)\n",
        "        ax.set_title(title, fontsize=12)\n",
        "        ax.axis('off')\n",
        "\n",
        "    def visualize_norm(data, ax, title):\n",
        "        rgb_norm = data[:3, :, :].transpose(1, 2, 0)\n",
        "        rgb_norm_display = (rgb_norm + 3) / 6\n",
        "        ax.imshow(np.clip(rgb_norm_display, 0, 1))\n",
        "        ax.set_title(title, fontsize=12)\n",
        "        ax.axis('off')\n",
        "\n",
        "    visualize_rgb(yes_data_before, axes[0, 0], \"'Yes' Patch (Before Normalization)\")\n",
        "    visualize_rgb(no_data_before, axes[0, 1], \"'No' Patch (Before Normalization)\")\n",
        "    visualize_norm(yes_data_norm, axes[1, 0], \"'Yes' Patch (After Normalization)\")\n",
        "    visualize_norm(no_data_norm, axes[1, 1], \"'No' Patch (After Normalization)\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Run the Verification ---\n",
        "if __name__ == \"__main__\":\n",
        "    verify_normalization(AUGMENTED_MANIFEST_PATH, NORMALIZED_MANIFEST_PATH, STATS_FILE_PATH)\n",
        "\n"
      ],
      "metadata": {
        "id": "jkM7UERVEUce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "# --- Configuration & Setup ---\n",
        "# Set our random seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# --- NEW DATA LOADING SECTION ---\n",
        "try:\n",
        "    MANIFEST_PATH = \"/content/final_augmented_dataset_labels.csv\"\n",
        "    manifest_df = pd.read_csv(MANIFEST_PATH)\n",
        "    print(f\"Successfully loaded dataset manifest with {len(manifest_df)} entries.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ ERROR: Could not find the manifest file at {MANIFEST_PATH}\")\n",
        "    print(\"Please ensure the augmentation script has been run successfully.\")\n",
        "    exit()\n",
        "\n",
        "# --- BATCH PREPROCESSING ---\n",
        "# Set storage folder\n",
        "OUTPUT_DIR = \"patch_store\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "TARGET_HEIGHT, TARGET_WIDTH = 256, 256\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "X_batch, Y_batch = [], []\n",
        "batch_idx = 0\n",
        "\n",
        "# --- CRUCIAL FIX: Shuffle the manifest before creating batches ---\n",
        "# This ensures that each .npz file contains a random mix of 'yes' and 'no' patches.\n",
        "manifest_df = manifest_df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "print(\"Shuffled the dataset manifest to ensure mixed batches.\")\n",
        "\n",
        "\n",
        "# The main loop now iterates through our SHUFFLED manifest DataFrame\n",
        "for index, row in tqdm(manifest_df.iterrows(), total=len(manifest_df), desc=\"Processing Patches\"):\n",
        "    patch_path = row['filepath']\n",
        "    label = row['label']\n",
        "\n",
        "    with rasterio.open(patch_path) as src:\n",
        "        img = src.read().astype(np.float32)\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "    img = cv2.resize(\n",
        "        img,\n",
        "        (TARGET_WIDTH, TARGET_HEIGHT),\n",
        "        interpolation=cv2.INTER_LINEAR\n",
        "    )\n",
        "    img = img / 10000.0\n",
        "\n",
        "    X_batch.append(img)\n",
        "    Y_batch.append(label)\n",
        "\n",
        "    if len(X_batch) >= BATCH_SIZE:\n",
        "        X_batch_np = np.stack(X_batch)\n",
        "        Y_batch_np = np.array(Y_batch)\n",
        "        np.savez_compressed(\n",
        "            os.path.join(OUTPUT_DIR, f\"batch_{batch_idx:04d}.npz\"),\n",
        "            X=X_batch_np, Y=Y_batch_np\n",
        "        )\n",
        "        batch_idx += 1\n",
        "        X_batch, Y_batch = [], []\n",
        "\n",
        "if len(X_batch) > 0:\n",
        "    X_batch_np = np.stack(X_batch)\n",
        "    Y_batch_np = np.array(Y_batch)\n",
        "    np.savez_compressed(\n",
        "        os.path.join(OUTPUT_DIR, f\"batch_{batch_idx:04d}.npz\"),\n",
        "        X=X_batch_np, Y=Y_batch_np\n",
        "    )\n",
        "\n",
        "print(f\"\\nPreprocessing complete. Saved {batch_idx + 1} batches to '{OUTPUT_DIR}'.\")\n",
        "\n",
        "\n",
        "# --- TF DATASET PREPARATION ---\n",
        "all_files = sorted(glob.glob(\"patch_store/*.npz\"))\n",
        "np.random.shuffle(all_files)\n",
        "\n",
        "train_split_index = int(len(all_files) * 0.8)\n",
        "train_files = all_files[:train_split_index]\n",
        "val_files = all_files[train_split_index:]\n",
        "\n",
        "print(f\"\\nTotal batches: {len(all_files)}\")\n",
        "print(f\"Training batches: {len(train_files)}\")\n",
        "print(f\"Validation batches: {len(val_files)}\")\n",
        "\n",
        "\n",
        "def npz_loader_cls(path):\n",
        "    with np.load(path.numpy().decode(\"utf-8\")) as data:\n",
        "        X = data[\"X\"].astype(np.float32)\n",
        "        Y = data[\"Y\"].astype(np.float32)\n",
        "    return X, Y\n",
        "\n",
        "def tf_wrapper(path):\n",
        "    X, Y = tf.py_function(npz_loader_cls, [path], [tf.float32, tf.float32])\n",
        "    X.set_shape([None, TARGET_HEIGHT, TARGET_WIDTH, 4])\n",
        "    Y.set_shape([None])\n",
        "    return tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "\n",
        "def make_cls_dataset(file_list, batch_size, shuffle=True, repeat=True):\n",
        "    files = tf.data.Dataset.from_tensor_slices(file_list)\n",
        "    if shuffle:\n",
        "        files = files.shuffle(len(file_list))\n",
        "    ds = files.interleave(\n",
        "        lambda f: tf_wrapper(f),\n",
        "        cycle_length=4,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(2048)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    if repeat:\n",
        "        ds = ds.repeat()\n",
        "    return ds\n",
        "\n",
        "MODEL_BATCH_SIZE = 32\n",
        "train_ds = make_cls_dataset(train_files, batch_size=MODEL_BATCH_SIZE, shuffle=True)\n",
        "val_ds = make_cls_dataset(val_files, batch_size=MODEL_BATCH_SIZE, shuffle=False, repeat=False)\n",
        "\n",
        "\n",
        "# --- MODEL DEFINITION & TRAINING ---\n",
        "for X_sample, _ in train_ds.take(1):\n",
        "    input_shape = X_sample.shape[1:]\n",
        "    break\n",
        "\n",
        "inputs = layers.Input(shape=input_shape)\n",
        "x = layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x) # Dropout layer removed as requested\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "def count_samples(files):\n",
        "    total = 0\n",
        "    for f in files:\n",
        "        total += np.load(f)[\"X\"].shape[0]\n",
        "    return total\n",
        "\n",
        "n_train = count_samples(train_files)\n",
        "n_val = count_samples(val_files)\n",
        "\n",
        "steps_per_epoch = max(1, n_train // MODEL_BATCH_SIZE)\n",
        "validation_steps = max(1, n_val // MODEL_BATCH_SIZE)\n",
        "\n",
        "# --- UPDATED CALLBACKS ---\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_accuracy\",  # CHANGE 1: Monitor validation accuracy\n",
        "        patience=3,              # CHANGE 2: Stop after 3 epochs with no improvement\n",
        "        restore_best_weights=True\n",
        "    )]\n",
        "\n",
        "# --- Run the model ---\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=25,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "OOljmU4TIXE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Ensure you have the 'history' object from model.fit() ---\n",
        "\n",
        "# --- Create the Plot ---\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation Loss\")\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label=\"Training Accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# --- Title and Caption ---\n",
        "fig.suptitle(\"Figure 1: Training Performance for the Enhanced Dataset\", fontsize=16, weight='bold')\n",
        "\n",
        "caption = (\n",
        "    \"Model performance on the enhanced dataset, which was balanced by creating and augmenting a 'no solar panel' class. \"\n",
        "    \"The validation accuracy immediately reached 100%, suggesting the model may be overfitting or exploiting simple differences between the classes. \"\n",
        "    \"Training was halted after 3 epochs by the EarlyStopping callback as no further improvement was observed.\"\n",
        ")\n",
        "\n",
        "# Added wrap=True to format the caption text into a paragraph\n",
        "fig.text(0.5, -0.02, caption, ha='center', fontsize=12, wrap=True)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.1, 1, 0.96]) # Adjust for suptitle\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGX4qR_LeNVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_patch_predictions_grid(dataset, model, n_rows=2, n_cols=5):\n",
        "    \"\"\"\n",
        "    Display predictions in a grid: n_rows x n_cols\n",
        "    Includes histogram stretch for better visualization of RGB patches.\n",
        "    \"\"\"\n",
        "    def stretch(img):\n",
        "        \"\"\"Contrast stretch to 0–1 for display.\"\"\"\n",
        "        img = img.astype(np.float32)\n",
        "        p2, p98 = np.percentile(img, (2, 98))\n",
        "        img = np.clip((img - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "        return img\n",
        "\n",
        "    for X, Y_true in dataset.take(1):\n",
        "        # live classification of the patch using the trained model\n",
        "        Y_pred = model.predict(X, verbose=0)\n",
        "        n_total = min(n_rows * n_cols, X.shape[0])\n",
        "\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i in range(n_total):\n",
        "            rgb = X[i, :, :, :3].numpy()\n",
        "            rgb = stretch(rgb)  # apply histogram stretch\n",
        "            axes[i].imshow(rgb)\n",
        "            axes[i].set_title(f\"T:{int(Y_true[i].numpy())}\\nP:{Y_pred[i,0]:.2f}\")\n",
        "            axes[i].axis(\"off\")\n",
        "\n",
        "        # hide any unused axes\n",
        "        for i in range(n_total, len(axes)):\n",
        "            axes[i].axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example\n",
        "show_patch_predictions_grid(val_ds, model, n_rows=1, n_cols=5)"
      ],
      "metadata": {
        "id": "-08xCh_5eXzH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}